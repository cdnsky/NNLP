{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1voLia8xeIwIQCX5XFGMU4Py7Tsy0AWMp #modified wikinews_extractor \n",
        "!unzip -qq wikinews_extractor.zip\n",
        "\n",
        "!gdown --id  1XZUtCYus8umDXHZQgZkx_An5FOiVyRYr #modified run_parse_wikinews_i18n.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5SN0Fw7vkT-",
        "outputId": "43c1b06a-2c90-4969-e4f9-c4fce73a17f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1voLia8xeIwIQCX5XFGMU4Py7Tsy0AWMp\n",
            "To: /content/wikinews_extractor.zip\n",
            "100% 22.5k/22.5k [00:00<00:00, 25.5MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XZUtCYus8umDXHZQgZkx_An5FOiVyRYr\n",
            "To: /content/run_parse_wikinews_i18n.sh\n",
            "100% 1.87k/1.87k [00:00<00:00, 2.32MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download and preprocessing raw mewsli-9 dataset\n",
        "%%bash\n",
        "#download github repo for preprocess mewsli-9 dataset\n",
        "\n",
        "gdown --id 1_W_B0kOG3bLnnXRluUa1sptUWRKcqsDy # mel.zip \n",
        "unzip -qq mel.zip\n",
        "\n",
        "mv mel/mewsli-9 mewsli-9\n",
        "mv mel/tools tools\n",
        "\n",
        "sh mel/get-mewsli-9.sh\n",
        "pip install -r wikinews_extractor/requirements.txt\n",
        "mv -u run_parse_wikinews_i18n.sh mewsli-9/\n",
        "bash mewsli-9/run_parse_wikinews_i18n.sh"
      ],
      "metadata": {
        "id": "8FMNkpQ4BLQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be728a10-88e9-4c5f-e790-aaf676994e65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  mewsli-9.zip\n",
            "   creating: ./mewsli-9/output/dataset/ar/\n",
            "  inflating: ./mewsli-9/output/dataset/ar/mentions.tsv  \n",
            "  inflating: ./mewsli-9/output/dataset/ar/docs.tsv  \n",
            "   creating: ./mewsli-9/output/dataset/de/\n",
            "  inflating: ./mewsli-9/output/dataset/de/mentions.tsv  \n",
            "  inflating: ./mewsli-9/output/dataset/de/docs.tsv  \n",
            "   creating: ./mewsli-9/output/dataset/en/\n",
            "  inflating: ./mewsli-9/output/dataset/en/mentions.tsv  \n",
            "  inflating: ./mewsli-9/output/dataset/en/docs.tsv  \n",
            "   creating: ./mewsli-9/output/dataset/es/\n",
            "  inflating: ./mewsli-9/output/dataset/es/mentions.tsv  \n",
            "  inflating: ./mewsli-9/output/dataset/es/docs.tsv  \n",
            "   creating: ./mewsli-9/output/dataset/fa/\n",
            "  inflating: ./mewsli-9/output/dataset/fa/mentions.tsv  \n",
            "  inflating: ./mewsli-9/output/dataset/fa/docs.tsv  \n",
            "   creating: ./mewsli-9/output/dataset/ja/\n",
            "  inflating: ./mewsli-9/output/dataset/ja/mentions.tsv  \n",
            "  inflating: ./mewsli-9/output/dataset/ja/docs.tsv  \n",
            "   creating: ./mewsli-9/output/dataset/sr/\n",
            "  inflating: ./mewsli-9/output/dataset/sr/mentions.tsv  \n",
            "  inflating: ./mewsli-9/output/dataset/sr/docs.tsv  \n",
            "   creating: ./mewsli-9/output/dataset/ta/\n",
            "  inflating: ./mewsli-9/output/dataset/ta/mentions.tsv  \n",
            "  inflating: ./mewsli-9/output/dataset/ta/docs.tsv  \n",
            "   creating: ./mewsli-9/output/dataset/tr/\n",
            "  inflating: ./mewsli-9/output/dataset/tr/mentions.tsv  \n",
            "  inflating: ./mewsli-9/output/dataset/tr/docs.tsv  \n",
            ">Download 'ar'...\n",
            ">Download 'de'...\n",
            ">Download 'en'...\n",
            ">Download 'es'...\n",
            ">Download 'fa'...\n",
            ">Download 'ja'...\n",
            ">Download 'sr'...\n",
            ">Download 'ta'...\n",
            ">Download 'tr'...\n",
            ">Verify...\n",
            "arwikinews-20190101-pages-articles.xml.bz2: OK\n",
            "dewikinews-20190101-pages-articles.xml.bz2: OK\n",
            "enwikinews-20190101-pages-articles.xml.bz2: OK\n",
            "eswikinews-20190101-pages-articles.xml.bz2: OK\n",
            "fawikinews-20190101-pages-articles.xml.bz2: OK\n",
            "jawikinews-20190101-pages-articles.xml.bz2: OK\n",
            "srwikinews-20190101-pages-articles.xml.bz2: OK\n",
            "tawikinews-20190101-pages-articles.xml.bz2: OK\n",
            "trwikinews-20190101-pages-articles.xml.bz2: OK\n",
            "\n",
            ">Done: mewsli-9/output/download\n",
            ">Download external wikiextractor tool...\n",
            "\n",
            ">Apply custom patch..\n",
            "\n",
            ">Done: tools/wikiextractor_repo\n",
            "Sun May 29 22:36:26 UTC 2022\n",
            "ar\n",
            "Sun May 29 22:38:51 UTC 2022\n",
            "de\n",
            "Sun May 29 22:40:14 UTC 2022\n",
            "en\n",
            "Sun May 29 22:46:47 UTC 2022\n",
            "es\n",
            "Sun May 29 22:50:59 UTC 2022\n",
            "fa\n",
            "Sun May 29 22:51:13 UTC 2022\n",
            "ja\n",
            "Sun May 29 22:51:35 UTC 2022\n",
            "sr\n",
            "Sun May 29 22:55:11 UTC 2022\n",
            "ta\n",
            "Sun May 29 22:55:28 UTC 2022\n",
            "tr\n",
            "Sun May 29 22:55:42 UTC 2022\n",
            ">Done: mewsli-9/output/wikiextractor\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: absl_py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from -r wikinews_extractor/requirements.txt (line 1)) (1.0.0)\n",
            "Collecting bz2file>=0.98\n",
            "  Downloading bz2file-0.98.tar.gz (11 kB)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from -r wikinews_extractor/requirements.txt (line 3)) (1.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl_py>=0.9.0->-r wikinews_extractor/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->-r wikinews_extractor/requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->-r wikinews_extractor/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->-r wikinews_extractor/requirements.txt (line 3)) (2022.1)\n",
            "Building wheels for collected packages: bz2file\n",
            "  Building wheel for bz2file (setup.py): started\n",
            "  Building wheel for bz2file (setup.py): finished with status 'done'\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-py3-none-any.whl size=6882 sha256=24992c1df644919055e82718e351d9c55c6344d35a4bbf5933bea571344fa0d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/ce/8d/b5f76b602b16a8a39f2ded74189cf5f09fc4a87bea16c54a8b\n",
            "Successfully built bz2file\n",
            "Installing collected packages: bz2file\n",
            "Successfully installed bz2file-0.98\n",
            "Sun May 29 22:55:47 UTC 2022\n",
            ">Parse 'ar'...\n",
            "\n",
            "Sun May 29 22:55:47 UTC 2022\n",
            ">Parse 'de'...\n",
            "\n",
            "Sun May 29 22:55:47 UTC 2022\n",
            ">Parse 'en'...\n",
            "\n",
            "Sun May 29 22:55:47 UTC 2022\n",
            ">Parse 'es'...\n",
            "\n",
            "Sun May 29 22:55:47 UTC 2022\n",
            ">Parse 'fa'...\n",
            "\n",
            "Sun May 29 22:55:47 UTC 2022\n",
            ">Parse 'ja'...\n",
            "\n",
            "Sun May 29 22:55:47 UTC 2022\n",
            ">Parse 'sr'...\n",
            "\n",
            "Sun May 29 22:55:47 UTC 2022\n",
            ">Parse 'ta'...\n",
            "\n",
            "Sun May 29 22:55:48 UTC 2022\n",
            ">Parse 'tr'...\n",
            "\n",
            "Sun May 29 22:58:59 UTC 2022\n",
            ">Done: mewsli-9/output/dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_W_B0kOG3bLnnXRluUa1sptUWRKcqsDy\n",
            "To: /content/mel.zip\n",
            "\r  0%|          | 0.00/84.0k [00:00<?, ?B/s]\r100%|██████████| 84.0k/84.0k [00:00<00:00, 67.4MB/s]\n",
            "+ DATASET_DIR=./mewsli-9/output/dataset\n",
            "+ mkdir -p ./mewsli-9/output/dataset\n",
            "+ wget https://storage.googleapis.com/gresearch/mewsli/mewsli-9.zip\n",
            "--2022-05-29 22:33:46--  https://storage.googleapis.com/gresearch/mewsli/mewsli-9.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.188.208, 142.251.33.208, 172.217.164.144, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.188.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10155722 (9.7M) [application/zip]\n",
            "Saving to: ‘mewsli-9.zip’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 37.8M 0s\n",
            "    50K .......... .......... .......... .......... ..........  1% 46.4M 0s\n",
            "   100K .......... .......... .......... .......... ..........  1% 64.5M 0s\n",
            "   150K .......... .......... .......... .......... ..........  2% 49.6M 0s\n",
            "   200K .......... .......... .......... .......... ..........  2% 56.4M 0s\n",
            "   250K .......... .......... .......... .......... ..........  3% 59.3M 0s\n",
            "   300K .......... .......... .......... .......... ..........  3% 56.2M 0s\n",
            "   350K .......... .......... .......... .......... ..........  4% 58.4M 0s\n",
            "   400K .......... .......... .......... .......... ..........  4% 44.3M 0s\n",
            "   450K .......... .......... .......... .......... ..........  5% 43.4M 0s\n",
            "   500K .......... .......... .......... .......... ..........  5% 71.3M 0s\n",
            "   550K .......... .......... .......... .......... ..........  6% 72.4M 0s\n",
            "   600K .......... .......... .......... .......... ..........  6% 59.7M 0s\n",
            "   650K .......... .......... .......... .......... ..........  7% 45.4M 0s\n",
            "   700K .......... .......... .......... .......... ..........  7% 68.2M 0s\n",
            "   750K .......... .......... .......... .......... ..........  8% 73.6M 0s\n",
            "   800K .......... .......... .......... .......... ..........  8% 66.3M 0s\n",
            "   850K .......... .......... .......... .......... ..........  9% 58.5M 0s\n",
            "   900K .......... .......... .......... .......... ..........  9% 63.1M 0s\n",
            "   950K .......... .......... .......... .......... .......... 10% 72.5M 0s\n",
            "  1000K .......... .......... .......... .......... .......... 10% 60.9M 0s\n",
            "  1050K .......... .......... .......... .......... .......... 11%  172M 0s\n",
            "  1100K .......... .......... .......... .......... .......... 11%  159M 0s\n",
            "  1150K .......... .......... .......... .......... .......... 12%  136M 0s\n",
            "  1200K .......... .......... .......... .......... .......... 12%  176M 0s\n",
            "  1250K .......... .......... .......... .......... .......... 13%  170M 0s\n",
            "  1300K .......... .......... .......... .......... .......... 13%  236M 0s\n",
            "  1350K .......... .......... .......... .......... .......... 14%  161M 0s\n",
            "  1400K .......... .......... .......... .......... .......... 14%  187M 0s\n",
            "  1450K .......... .......... .......... .......... .......... 15%  172M 0s\n",
            "  1500K .......... .......... .......... .......... .......... 15%  221M 0s\n",
            "  1550K .......... .......... .......... .......... .......... 16%  211M 0s\n",
            "  1600K .......... .......... .......... .......... .......... 16%  142M 0s\n",
            "  1650K .......... .......... .......... .......... .......... 17%  153M 0s\n",
            "  1700K .......... .......... .......... .......... .......... 17%  123M 0s\n",
            "  1750K .......... .......... .......... .......... .......... 18%  145M 0s\n",
            "  1800K .......... .......... .......... .......... .......... 18%  173M 0s\n",
            "  1850K .......... .......... .......... .......... .......... 19%  137M 0s\n",
            "  1900K .......... .......... .......... .......... .......... 19%  134M 0s\n",
            "  1950K .......... .......... .......... .......... .......... 20%  125M 0s\n",
            "  2000K .......... .......... .......... .......... .......... 20%  184M 0s\n",
            "  2050K .......... .......... .......... .......... .......... 21%  169M 0s\n",
            "  2100K .......... .......... .......... .......... .......... 21%  146M 0s\n",
            "  2150K .......... .......... .......... .......... .......... 22%  135M 0s\n",
            "  2200K .......... .......... .......... .......... .......... 22%  197M 0s\n",
            "  2250K .......... .......... .......... .......... .......... 23%  193M 0s\n",
            "  2300K .......... .......... .......... .......... .......... 23%  173M 0s\n",
            "  2350K .......... .......... .......... .......... .......... 24% 88.8M 0s\n",
            "  2400K .......... .......... .......... .......... .......... 24%  103M 0s\n",
            "  2450K .......... .......... .......... .......... .......... 25%  140M 0s\n",
            "  2500K .......... .......... .......... .......... .......... 25%  171M 0s\n",
            "  2550K .......... .......... .......... .......... .......... 26%  140M 0s\n",
            "  2600K .......... .......... .......... .......... .......... 26%  142M 0s\n",
            "  2650K .......... .......... .......... .......... .......... 27%  116M 0s\n",
            "  2700K .......... .......... .......... .......... .......... 27%  159M 0s\n",
            "  2750K .......... .......... .......... .......... .......... 28%  173M 0s\n",
            "  2800K .......... .......... .......... .......... .......... 28%  155M 0s\n",
            "  2850K .......... .......... .......... .......... .......... 29%  146M 0s\n",
            "  2900K .......... .......... .......... .......... .......... 29%  154M 0s\n",
            "  2950K .......... .......... .......... .......... .......... 30%  119M 0s\n",
            "  3000K .......... .......... .......... .......... .......... 30%  162M 0s\n",
            "  3050K .......... .......... .......... .......... .......... 31%  175M 0s\n",
            "  3100K .......... .......... .......... .......... .......... 31%  148M 0s\n",
            "  3150K .......... .......... .......... .......... .......... 32%  105M 0s\n",
            "  3200K .......... .......... .......... .......... .......... 32%  185M 0s\n",
            "  3250K .......... .......... .......... .......... .......... 33%  187M 0s\n",
            "  3300K .......... .......... .......... .......... .......... 33%  194M 0s\n",
            "  3350K .......... .......... .......... .......... .......... 34%  143M 0s\n",
            "  3400K .......... .......... .......... .......... .......... 34%  153M 0s\n",
            "  3450K .......... .......... .......... .......... .......... 35%  189M 0s\n",
            "  3500K .......... .......... .......... .......... .......... 35%  194M 0s\n",
            "  3550K .......... .......... .......... .......... .......... 36%  155M 0s\n",
            "  3600K .......... .......... .......... .......... .......... 36%  183M 0s\n",
            "  3650K .......... .......... .......... .......... .......... 37%  176M 0s\n",
            "  3700K .......... .......... .......... .......... .......... 37%  194M 0s\n",
            "  3750K .......... .......... .......... .......... .......... 38%  174M 0s\n",
            "  3800K .......... .......... .......... .......... .......... 38%  185M 0s\n",
            "  3850K .......... .......... .......... .......... .......... 39%  189M 0s\n",
            "  3900K .......... .......... .......... .......... .......... 39%  195M 0s\n",
            "  3950K .......... .......... .......... .......... .......... 40%  176M 0s\n",
            "  4000K .......... .......... .......... .......... .......... 40%  189M 0s\n",
            "  4050K .......... .......... .......... .......... .......... 41% 5.73M 0s\n",
            "  4100K .......... .......... .......... .......... .......... 41% 43.4M 0s\n",
            "  4150K .......... .......... .......... .......... .......... 42%  130M 0s\n",
            "  4200K .......... .......... .......... .......... .......... 42%  163M 0s\n",
            "  4250K .......... .......... .......... .......... .......... 43%  147M 0s\n",
            "  4300K .......... .......... .......... .......... .......... 43% 64.0M 0s\n",
            "  4350K .......... .......... .......... .......... .......... 44% 64.4M 0s\n",
            "  4400K .......... .......... .......... .......... .......... 44% 46.7M 0s\n",
            "  4450K .......... .......... .......... .......... .......... 45%  169M 0s\n",
            "  4500K .......... .......... .......... .......... .......... 45% 31.8M 0s\n",
            "  4550K .......... .......... .......... .......... .......... 46%  221M 0s\n",
            "  4600K .......... .......... .......... .......... .......... 46%  140M 0s\n",
            "  4650K .......... .......... .......... .......... .......... 47%  180M 0s\n",
            "  4700K .......... .......... .......... .......... .......... 47%  188M 0s\n",
            "  4750K .......... .......... .......... .......... .......... 48%  254M 0s\n",
            "  4800K .......... .......... .......... .......... .......... 48%  174M 0s\n",
            "  4850K .......... .......... .......... .......... .......... 49%  258M 0s\n",
            "  4900K .......... .......... .......... .......... .......... 49%  212M 0s\n",
            "  4950K .......... .......... .......... .......... .......... 50%  215M 0s\n",
            "  5000K .......... .......... .......... .......... .......... 50%  212M 0s\n",
            "  5050K .......... .......... .......... .......... .......... 51%  194M 0s\n",
            "  5100K .......... .......... .......... .......... .......... 51%  229M 0s\n",
            "  5150K .......... .......... .......... .......... .......... 52%  223M 0s\n",
            "  5200K .......... .......... .......... .......... .......... 52%  173M 0s\n",
            "  5250K .......... .......... .......... .......... .......... 53%  260M 0s\n",
            "  5300K .......... .......... .......... .......... .......... 53%  217M 0s\n",
            "  5350K .......... .......... .......... .......... .......... 54% 21.6M 0s\n",
            "  5400K .......... .......... .......... .......... .......... 54%  189M 0s\n",
            "  5450K .......... .......... .......... .......... .......... 55%  245M 0s\n",
            "  5500K .......... .......... .......... .......... .......... 55%  219M 0s\n",
            "  5550K .......... .......... .......... .......... .......... 56%  196M 0s\n",
            "  5600K .......... .......... .......... .......... .......... 56%  240M 0s\n",
            "  5650K .......... .......... .......... .......... .......... 57%  240M 0s\n",
            "  5700K .......... .......... .......... .......... .......... 57%  223M 0s\n",
            "  5750K .......... .......... .......... .......... .......... 58%  165M 0s\n",
            "  5800K .......... .......... .......... .......... .......... 58%  146M 0s\n",
            "  5850K .......... .......... .......... .......... .......... 59%  212M 0s\n",
            "  5900K .......... .......... .......... .......... .......... 59%  202M 0s\n",
            "  5950K .......... .......... .......... .......... .......... 60%  168M 0s\n",
            "  6000K .......... .......... .......... .......... .......... 61%  147M 0s\n",
            "  6050K .......... .......... .......... .......... .......... 61%  219M 0s\n",
            "  6100K .......... .......... .......... .......... .......... 62%  204M 0s\n",
            "  6150K .......... .......... .......... .......... .......... 62%  191M 0s\n",
            "  6200K .......... .......... .......... .......... .......... 63%  160M 0s\n",
            "  6250K .......... .......... .......... .......... .......... 63%  196M 0s\n",
            "  6300K .......... .......... .......... .......... .......... 64%  194M 0s\n",
            "  6350K .......... .......... .......... .......... .......... 64%  204M 0s\n",
            "  6400K .......... .......... .......... .......... .......... 65%  172M 0s\n",
            "  6450K .......... .......... .......... .......... .......... 65%  202M 0s\n",
            "  6500K .......... .......... .......... .......... .......... 66%  188M 0s\n",
            "  6550K .......... .......... .......... .......... .......... 66%  209M 0s\n",
            "  6600K .......... .......... .......... .......... .......... 67%  163M 0s\n",
            "  6650K .......... .......... .......... .......... .......... 67%  187M 0s\n",
            "  6700K .......... .......... .......... .......... .......... 68%  173M 0s\n",
            "  6750K .......... .......... .......... .......... .......... 68%  181M 0s\n",
            "  6800K .......... .......... .......... .......... .......... 69%  180M 0s\n",
            "  6850K .......... .......... .......... .......... .......... 69%  229M 0s\n",
            "  6900K .......... .......... .......... .......... .......... 70%  190M 0s\n",
            "  6950K .......... .......... .......... .......... .......... 70%  172M 0s\n",
            "  7000K .......... .......... .......... .......... .......... 71%  183M 0s\n",
            "  7050K .......... .......... .......... .......... .......... 71%  196M 0s\n",
            "  7100K .......... .......... .......... .......... .......... 72%  208M 0s\n",
            "  7150K .......... .......... .......... .......... .......... 72%  196M 0s\n",
            "  7200K .......... .......... .......... .......... .......... 73%  162M 0s\n",
            "  7250K .......... .......... .......... .......... .......... 73%  174M 0s\n",
            "  7300K .......... .......... .......... .......... .......... 74%  188M 0s\n",
            "  7350K .......... .......... .......... .......... .......... 74%  219M 0s\n",
            "  7400K .......... .......... .......... .......... .......... 75%  182M 0s\n",
            "  7450K .......... .......... .......... .......... .......... 75%  173M 0s\n",
            "  7500K .......... .......... .......... .......... .......... 76%  197M 0s\n",
            "  7550K .......... .......... .......... .......... .......... 76%  204M 0s\n",
            "  7600K .......... .......... .......... .......... .......... 77%  179M 0s\n",
            "  7650K .......... .......... .......... .......... .......... 77%  170M 0s\n",
            "  7700K .......... .......... .......... .......... .......... 78%  203M 0s\n",
            "  7750K .......... .......... .......... .......... .......... 78%  213M 0s\n",
            "  7800K .......... .......... .......... .......... .......... 79%  166M 0s\n",
            "  7850K .......... .......... .......... .......... .......... 79%  197M 0s\n",
            "  7900K .......... .......... .......... .......... .......... 80%  192M 0s\n",
            "  7950K .......... .......... .......... .......... .......... 80%  200M 0s\n",
            "  8000K .......... .......... .......... .......... .......... 81%  185M 0s\n",
            "  8050K .......... .......... .......... .......... .......... 81%  211M 0s\n",
            "  8100K .......... .......... .......... .......... .......... 82%  199M 0s\n",
            "  8150K .......... .......... .......... .......... .......... 82%  200M 0s\n",
            "  8200K .......... .......... .......... .......... .......... 83%  185M 0s\n",
            "  8250K .......... .......... .......... .......... .......... 83%  171M 0s\n",
            "  8300K .......... .......... .......... .......... .......... 84%  190M 0s\n",
            "  8350K .......... .......... .......... .......... .......... 84%  229M 0s\n",
            "  8400K .......... .......... .......... .......... .......... 85%  173M 0s\n",
            "  8450K .......... .......... .......... .......... .......... 85%  196M 0s\n",
            "  8500K .......... .......... .......... .......... .......... 86%  189M 0s\n",
            "  8550K .......... .......... .......... .......... .......... 86%  194M 0s\n",
            "  8600K .......... .......... .......... .......... .......... 87%  185M 0s\n",
            "  8650K .......... .......... .......... .......... .......... 87%  180M 0s\n",
            "  8700K .......... .......... .......... .......... .......... 88%  213M 0s\n",
            "  8750K .......... .......... .......... .......... .......... 88%  185M 0s\n",
            "  8800K .......... .......... .......... .......... .......... 89%  180M 0s\n",
            "  8850K .......... .......... .......... .......... .......... 89%  202M 0s\n",
            "  8900K .......... .......... .......... .......... .......... 90%  203M 0s\n",
            "  8950K .......... .......... .......... .......... .......... 90%  213M 0s\n",
            "  9000K .......... .......... .......... .......... .......... 91%  173M 0s\n",
            "  9050K .......... .......... .......... .......... .......... 91%  208M 0s\n",
            "  9100K .......... .......... .......... .......... .......... 92%  217M 0s\n",
            "  9150K .......... .......... .......... .......... .......... 92%  188M 0s\n",
            "  9200K .......... .......... .......... .......... .......... 93%  192M 0s\n",
            "  9250K .......... .......... .......... .......... .......... 93%  201M 0s\n",
            "  9300K .......... .......... .......... .......... .......... 94%  218M 0s\n",
            "  9350K .......... .......... .......... .......... .......... 94%  227M 0s\n",
            "  9400K .......... .......... .......... .......... .......... 95%  192M 0s\n",
            "  9450K .......... .......... .......... .......... .......... 95%  205M 0s\n",
            "  9500K .......... .......... .......... .......... .......... 96%  205M 0s\n",
            "  9550K .......... .......... .......... .......... .......... 96%  226M 0s\n",
            "  9600K .......... .......... .......... .......... .......... 97%  182M 0s\n",
            "  9650K .......... .......... .......... .......... .......... 97%  210M 0s\n",
            "  9700K .......... .......... .......... .......... .......... 98%  199M 0s\n",
            "  9750K .......... .......... .......... .......... .......... 98%  219M 0s\n",
            "  9800K .......... .......... .......... .......... .......... 99%  199M 0s\n",
            "  9850K .......... .......... .......... .......... .......... 99%  207M 0s\n",
            "  9900K .......... .......                                    100%  218M=0.08s\n",
            "\n",
            "2022-05-29 22:33:46 (120 MB/s) - ‘mewsli-9.zip’ saved [10155722/10155722]\n",
            "\n",
            "+ unzip -d ./mewsli-9/output/dataset mewsli-9.zip\n",
            "+ bash mewsli-9/get_wikinews_dumps.sh\n",
            "++ dirname mewsli-9/get_wikinews_dumps.sh\n",
            "+ DEFAULT_OUTDIR=mewsli-9/output/download\n",
            "+ OUTDIR=mewsli-9/output/download\n",
            "+ DATE=20190101\n",
            "+ LANG_LIST=(ar de en es fa ja sr ta tr)\n",
            "+++ dirname mewsli-9/get_wikinews_dumps.sh\n",
            "++ readlink -e mewsli-9\n",
            "+ CHECKSUMS=/content/mewsli-9/dump_checksums.txt\n",
            "+ mkdir -p mewsli-9/output/download\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ echo '>Download '\\''ar'\\''...'\n",
            "+ filename=arwikinews-20190101-pages-articles.xml.bz2\n",
            "+ url=https://archive.org/download/arwikinews-20190101/arwikinews-20190101-pages-articles.xml.bz2\n",
            "+ wget -a mewsli-9/output/download/wget.log -O mewsli-9/output/download/arwikinews-20190101-pages-articles.xml.bz2 https://archive.org/download/arwikinews-20190101/arwikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ echo '>Download '\\''de'\\''...'\n",
            "+ filename=dewikinews-20190101-pages-articles.xml.bz2\n",
            "+ url=https://archive.org/download/dewikinews-20190101/dewikinews-20190101-pages-articles.xml.bz2\n",
            "+ wget -a mewsli-9/output/download/wget.log -O mewsli-9/output/download/dewikinews-20190101-pages-articles.xml.bz2 https://archive.org/download/dewikinews-20190101/dewikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ echo '>Download '\\''en'\\''...'\n",
            "+ filename=enwikinews-20190101-pages-articles.xml.bz2\n",
            "+ url=https://archive.org/download/enwikinews-20190101/enwikinews-20190101-pages-articles.xml.bz2\n",
            "+ wget -a mewsli-9/output/download/wget.log -O mewsli-9/output/download/enwikinews-20190101-pages-articles.xml.bz2 https://archive.org/download/enwikinews-20190101/enwikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ echo '>Download '\\''es'\\''...'\n",
            "+ filename=eswikinews-20190101-pages-articles.xml.bz2\n",
            "+ url=https://archive.org/download/eswikinews-20190101/eswikinews-20190101-pages-articles.xml.bz2\n",
            "+ wget -a mewsli-9/output/download/wget.log -O mewsli-9/output/download/eswikinews-20190101-pages-articles.xml.bz2 https://archive.org/download/eswikinews-20190101/eswikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ echo '>Download '\\''fa'\\''...'\n",
            "+ filename=fawikinews-20190101-pages-articles.xml.bz2\n",
            "+ url=https://archive.org/download/fawikinews-20190101/fawikinews-20190101-pages-articles.xml.bz2\n",
            "+ wget -a mewsli-9/output/download/wget.log -O mewsli-9/output/download/fawikinews-20190101-pages-articles.xml.bz2 https://archive.org/download/fawikinews-20190101/fawikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ echo '>Download '\\''ja'\\''...'\n",
            "+ filename=jawikinews-20190101-pages-articles.xml.bz2\n",
            "+ url=https://archive.org/download/jawikinews-20190101/jawikinews-20190101-pages-articles.xml.bz2\n",
            "+ wget -a mewsli-9/output/download/wget.log -O mewsli-9/output/download/jawikinews-20190101-pages-articles.xml.bz2 https://archive.org/download/jawikinews-20190101/jawikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ echo '>Download '\\''sr'\\''...'\n",
            "+ filename=srwikinews-20190101-pages-articles.xml.bz2\n",
            "+ url=https://archive.org/download/srwikinews-20190101/srwikinews-20190101-pages-articles.xml.bz2\n",
            "+ wget -a mewsli-9/output/download/wget.log -O mewsli-9/output/download/srwikinews-20190101-pages-articles.xml.bz2 https://archive.org/download/srwikinews-20190101/srwikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ echo '>Download '\\''ta'\\''...'\n",
            "+ filename=tawikinews-20190101-pages-articles.xml.bz2\n",
            "+ url=https://archive.org/download/tawikinews-20190101/tawikinews-20190101-pages-articles.xml.bz2\n",
            "+ wget -a mewsli-9/output/download/wget.log -O mewsli-9/output/download/tawikinews-20190101-pages-articles.xml.bz2 https://archive.org/download/tawikinews-20190101/tawikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ echo '>Download '\\''tr'\\''...'\n",
            "+ filename=trwikinews-20190101-pages-articles.xml.bz2\n",
            "+ url=https://archive.org/download/trwikinews-20190101/trwikinews-20190101-pages-articles.xml.bz2\n",
            "+ wget -a mewsli-9/output/download/wget.log -O mewsli-9/output/download/trwikinews-20190101-pages-articles.xml.bz2 https://archive.org/download/trwikinews-20190101/trwikinews-20190101-pages-articles.xml.bz2\n",
            "+ echo '>Verify...'\n",
            "+ [[ ! -f /content/mewsli-9/dump_checksums.txt ]]\n",
            "+ OLDPWD=/content\n",
            "+ cd mewsli-9/output/download\n",
            "+ md5sum -c /content/mewsli-9/dump_checksums.txt\n",
            "+ cd /content\n",
            "+ echo\n",
            "+ echo '>Done: mewsli-9/output/download'\n",
            "+ bash tools/get_wikiextractor.sh\n",
            "++ dirname tools/get_wikiextractor.sh\n",
            "+ DEFAULT_OUTDIR=tools/wikiextractor_repo\n",
            "+ OUTDIR=tools/wikiextractor_repo\n",
            "+ [[ ! -f tools/wikiextractor_repo/WikiExtractor.py ]]\n",
            "+++ dirname tools/get_wikiextractor.sh\n",
            "++ readlink -e tools\n",
            "+ PATCH=/content/tools/wikiextractor.patch\n",
            "+ [[ ! -f /content/tools/wikiextractor.patch ]]\n",
            "+ echo '>Download external wikiextractor tool...'\n",
            "+ OLDPWD=/content\n",
            "+ git clone https://github.com/attardi/wikiextractor.git tools/wikiextractor_repo\n",
            "Cloning into 'tools/wikiextractor_repo'...\n",
            "+ cd tools/wikiextractor_repo\n",
            "+ echo\n",
            "+ echo '>Apply custom patch..'\n",
            "+ git checkout -b linkfilter_off 16186e290d\n",
            "Switched to a new branch 'linkfilter_off'\n",
            "+ git apply /content/tools/wikiextractor.patch\n",
            "+ cd /content\n",
            "+ echo\n",
            "+ echo '>Done: tools/wikiextractor_repo'\n",
            "+ bash mewsli-9/run_wikiextractor.sh\n",
            "++ dirname mewsli-9/run_wikiextractor.sh\n",
            "+ BIN_DEFAULT=mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py\n",
            "+ WIKIEXTRACTOR=mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py\n",
            "++ dirname mewsli-9/run_wikiextractor.sh\n",
            "+ OUTPUT_BASE_DIR_DEFAULT=mewsli-9/output/wikiextractor\n",
            "+ OUTPUT_BASE_DIR=mewsli-9/output/wikiextractor\n",
            "+ TEMPLATES_DIR_DEFAULT=mewsli-9/output/wikiextractor/templates_cache\n",
            "+ TEMPLATES_DIR=mewsli-9/output/wikiextractor/templates_cache\n",
            "++ dirname mewsli-9/run_wikiextractor.sh\n",
            "+ INPUT_DUMP_DIR_DEFAULT=mewsli-9/output/download\n",
            "+ INPUT_DUMP_DIR=mewsli-9/output/download\n",
            "+ LANG_LIST=(ar de en es fa ja sr ta tr)\n",
            "+ [[ ! -x mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py ]]\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/templates_cache\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo ar\n",
            "+ templates=mewsli-9/output/wikiextractor/templates_cache/ar\n",
            "+ output_dir=mewsli-9/output/wikiextractor/ar\n",
            "+ input=mewsli-9/output/download/arwikinews-20190101-pages-articles.xml.bz2\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/ar\n",
            "+ mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py --templates mewsli-9/output/wikiextractor/templates_cache/ar --revision --links --sections --json --compress --output mewsli-9/output/wikiextractor/ar mewsli-9/output/download/arwikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo de\n",
            "+ templates=mewsli-9/output/wikiextractor/templates_cache/de\n",
            "+ output_dir=mewsli-9/output/wikiextractor/de\n",
            "+ input=mewsli-9/output/download/dewikinews-20190101-pages-articles.xml.bz2\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/de\n",
            "+ mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py --templates mewsli-9/output/wikiextractor/templates_cache/de --revision --links --sections --json --compress --output mewsli-9/output/wikiextractor/de mewsli-9/output/download/dewikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo en\n",
            "+ templates=mewsli-9/output/wikiextractor/templates_cache/en\n",
            "+ output_dir=mewsli-9/output/wikiextractor/en\n",
            "+ input=mewsli-9/output/download/enwikinews-20190101-pages-articles.xml.bz2\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/en\n",
            "+ mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py --templates mewsli-9/output/wikiextractor/templates_cache/en --revision --links --sections --json --compress --output mewsli-9/output/wikiextractor/en mewsli-9/output/download/enwikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo es\n",
            "+ templates=mewsli-9/output/wikiextractor/templates_cache/es\n",
            "+ output_dir=mewsli-9/output/wikiextractor/es\n",
            "+ input=mewsli-9/output/download/eswikinews-20190101-pages-articles.xml.bz2\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/es\n",
            "+ mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py --templates mewsli-9/output/wikiextractor/templates_cache/es --revision --links --sections --json --compress --output mewsli-9/output/wikiextractor/es mewsli-9/output/download/eswikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo fa\n",
            "+ templates=mewsli-9/output/wikiextractor/templates_cache/fa\n",
            "+ output_dir=mewsli-9/output/wikiextractor/fa\n",
            "+ input=mewsli-9/output/download/fawikinews-20190101-pages-articles.xml.bz2\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/fa\n",
            "+ mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py --templates mewsli-9/output/wikiextractor/templates_cache/fa --revision --links --sections --json --compress --output mewsli-9/output/wikiextractor/fa mewsli-9/output/download/fawikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo ja\n",
            "+ templates=mewsli-9/output/wikiextractor/templates_cache/ja\n",
            "+ output_dir=mewsli-9/output/wikiextractor/ja\n",
            "+ input=mewsli-9/output/download/jawikinews-20190101-pages-articles.xml.bz2\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/ja\n",
            "+ mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py --templates mewsli-9/output/wikiextractor/templates_cache/ja --revision --links --sections --json --compress --output mewsli-9/output/wikiextractor/ja mewsli-9/output/download/jawikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo sr\n",
            "+ templates=mewsli-9/output/wikiextractor/templates_cache/sr\n",
            "+ output_dir=mewsli-9/output/wikiextractor/sr\n",
            "+ input=mewsli-9/output/download/srwikinews-20190101-pages-articles.xml.bz2\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/sr\n",
            "+ mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py --templates mewsli-9/output/wikiextractor/templates_cache/sr --revision --links --sections --json --compress --output mewsli-9/output/wikiextractor/sr mewsli-9/output/download/srwikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo ta\n",
            "+ templates=mewsli-9/output/wikiextractor/templates_cache/ta\n",
            "+ output_dir=mewsli-9/output/wikiextractor/ta\n",
            "+ input=mewsli-9/output/download/tawikinews-20190101-pages-articles.xml.bz2\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/ta\n",
            "+ mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py --templates mewsli-9/output/wikiextractor/templates_cache/ta --revision --links --sections --json --compress --output mewsli-9/output/wikiextractor/ta mewsli-9/output/download/tawikinews-20190101-pages-articles.xml.bz2\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo tr\n",
            "+ templates=mewsli-9/output/wikiextractor/templates_cache/tr\n",
            "+ output_dir=mewsli-9/output/wikiextractor/tr\n",
            "+ input=mewsli-9/output/download/trwikinews-20190101-pages-articles.xml.bz2\n",
            "+ mkdir -p mewsli-9/output/wikiextractor/tr\n",
            "+ mewsli-9/../tools/wikiextractor_repo/WikiExtractor.py --templates mewsli-9/output/wikiextractor/templates_cache/tr --revision --links --sections --json --compress --output mewsli-9/output/wikiextractor/tr mewsli-9/output/download/trwikinews-20190101-pages-articles.xml.bz2\n",
            "+ date\n",
            "+ echo '>Done: mewsli-9/output/wikiextractor'\n",
            "+ virtualenv -p python3 ./env\n",
            "mel/get-mewsli-9.sh: 43: mel/get-mewsli-9.sh: virtualenv: not found\n",
            "++ dirname mewsli-9/run_parse_wikinews_i18n.sh\n",
            "+ INPUT_BASE_DIR_DEFAULT=mewsli-9/output/wikiextractor\n",
            "+ INPUT_BASE_DIR=mewsli-9/output/wikiextractor\n",
            "++ dirname mewsli-9/run_parse_wikinews_i18n.sh\n",
            "+ OUTPUT_BASE_DIR_DEFAULT=mewsli-9/output/dataset\n",
            "+ OUTPUT_BASE_DIR=mewsli-9/output/dataset\n",
            "+ LANG_LIST=(ar de en es fa ja sr ta tr)\n",
            "++ dirname mewsli-9/run_parse_wikinews_i18n.sh\n",
            "+ export PYTHONPATH=/env/python:mewsli-9/../../../\n",
            "+ PYTHONPATH=/env/python:mewsli-9/../../../\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ echo '>Parse '\\''ar'\\''...'\n",
            "+ output_dir=mewsli-9/output/dataset/ar\n",
            "+ mkdir -p mewsli-9/output/dataset/ar\n",
            "+ echo\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ python -m wikinews_extractor.parse_wikinews_i18n --mode=dataset '--wikinews_archive=mewsli-9/output/wikiextractor/ar/*/wiki_*.bz2' --language=ar --mention_index_path=mewsli-9/output/dataset/ar/mentions.tsv --doc_index_path=mewsli-9/output/dataset/ar/docs.tsv --output_dir_wiki=mewsli-9/output/dataset/ar/wiki --output_dir_text=mewsli-9/output/dataset/ar/text --logtostderr\n",
            "+ echo '>Parse '\\''de'\\''...'\n",
            "+ output_dir=mewsli-9/output/dataset/de\n",
            "+ mkdir -p mewsli-9/output/dataset/de\n",
            "+ echo\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ python -m wikinews_extractor.parse_wikinews_i18n --mode=dataset '--wikinews_archive=mewsli-9/output/wikiextractor/de/*/wiki_*.bz2' --language=de --mention_index_path=mewsli-9/output/dataset/de/mentions.tsv --doc_index_path=mewsli-9/output/dataset/de/docs.tsv --output_dir_wiki=mewsli-9/output/dataset/de/wiki --output_dir_text=mewsli-9/output/dataset/de/text --logtostderr\n",
            "+ echo '>Parse '\\''en'\\''...'\n",
            "+ output_dir=mewsli-9/output/dataset/en\n",
            "+ mkdir -p mewsli-9/output/dataset/en\n",
            "+ echo\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ python -m wikinews_extractor.parse_wikinews_i18n --mode=dataset '--wikinews_archive=mewsli-9/output/wikiextractor/en/*/wiki_*.bz2' --language=en --mention_index_path=mewsli-9/output/dataset/en/mentions.tsv --doc_index_path=mewsli-9/output/dataset/en/docs.tsv --output_dir_wiki=mewsli-9/output/dataset/en/wiki --output_dir_text=mewsli-9/output/dataset/en/text --logtostderr\n",
            "+ echo '>Parse '\\''es'\\''...'\n",
            "+ output_dir=mewsli-9/output/dataset/es\n",
            "+ mkdir -p mewsli-9/output/dataset/es\n",
            "+ echo\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ python -m wikinews_extractor.parse_wikinews_i18n --mode=dataset '--wikinews_archive=mewsli-9/output/wikiextractor/es/*/wiki_*.bz2' --language=es --mention_index_path=mewsli-9/output/dataset/es/mentions.tsv --doc_index_path=mewsli-9/output/dataset/es/docs.tsv --output_dir_wiki=mewsli-9/output/dataset/es/wiki --output_dir_text=mewsli-9/output/dataset/es/text --logtostderr\n",
            "+ echo '>Parse '\\''fa'\\''...'\n",
            "+ output_dir=mewsli-9/output/dataset/fa\n",
            "+ mkdir -p mewsli-9/output/dataset/fa\n",
            "+ echo\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ python -m wikinews_extractor.parse_wikinews_i18n --mode=dataset '--wikinews_archive=mewsli-9/output/wikiextractor/fa/*/wiki_*.bz2' --language=fa --mention_index_path=mewsli-9/output/dataset/fa/mentions.tsv --doc_index_path=mewsli-9/output/dataset/fa/docs.tsv --output_dir_wiki=mewsli-9/output/dataset/fa/wiki --output_dir_text=mewsli-9/output/dataset/fa/text --logtostderr\n",
            "+ echo '>Parse '\\''ja'\\''...'\n",
            "+ output_dir=mewsli-9/output/dataset/ja\n",
            "+ mkdir -p mewsli-9/output/dataset/ja\n",
            "+ echo\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ python -m wikinews_extractor.parse_wikinews_i18n --mode=dataset '--wikinews_archive=mewsli-9/output/wikiextractor/ja/*/wiki_*.bz2' --language=ja --mention_index_path=mewsli-9/output/dataset/ja/mentions.tsv --doc_index_path=mewsli-9/output/dataset/ja/docs.tsv --output_dir_wiki=mewsli-9/output/dataset/ja/wiki --output_dir_text=mewsli-9/output/dataset/ja/text --logtostderr\n",
            "+ echo '>Parse '\\''sr'\\''...'\n",
            "+ output_dir=mewsli-9/output/dataset/sr\n",
            "+ mkdir -p mewsli-9/output/dataset/sr\n",
            "+ echo\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ python -m wikinews_extractor.parse_wikinews_i18n --mode=dataset '--wikinews_archive=mewsli-9/output/wikiextractor/sr/*/wiki_*.bz2' --language=sr --mention_index_path=mewsli-9/output/dataset/sr/mentions.tsv --doc_index_path=mewsli-9/output/dataset/sr/docs.tsv --output_dir_wiki=mewsli-9/output/dataset/sr/wiki --output_dir_text=mewsli-9/output/dataset/sr/text --logtostderr\n",
            "+ echo '>Parse '\\''ta'\\''...'\n",
            "+ output_dir=mewsli-9/output/dataset/ta\n",
            "+ mkdir -p mewsli-9/output/dataset/ta\n",
            "+ echo\n",
            "+ for lang in ${LANG_LIST[@]}\n",
            "+ date\n",
            "+ python -m wikinews_extractor.parse_wikinews_i18n --mode=dataset '--wikinews_archive=mewsli-9/output/wikiextractor/ta/*/wiki_*.bz2' --language=ta --mention_index_path=mewsli-9/output/dataset/ta/mentions.tsv --doc_index_path=mewsli-9/output/dataset/ta/docs.tsv --output_dir_wiki=mewsli-9/output/dataset/ta/wiki --output_dir_text=mewsli-9/output/dataset/ta/text --logtostderr\n",
            "+ echo '>Parse '\\''tr'\\''...'\n",
            "+ output_dir=mewsli-9/output/dataset/tr\n",
            "+ mkdir -p mewsli-9/output/dataset/tr\n",
            "+ echo\n",
            "+ wait\n",
            "+ python -m wikinews_extractor.parse_wikinews_i18n --mode=dataset '--wikinews_archive=mewsli-9/output/wikiextractor/tr/*/wiki_*.bz2' --language=tr --mention_index_path=mewsli-9/output/dataset/tr/mentions.tsv --doc_index_path=mewsli-9/output/dataset/tr/docs.tsv --output_dir_wiki=mewsli-9/output/dataset/tr/wiki --output_dir_text=mewsli-9/output/dataset/tr/text --logtostderr\n",
            "+ date\n",
            "+ echo '>Done: mewsli-9/output/dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv mewsli-9/output/dataset ."
      ],
      "metadata": {
        "id": "JC0XSDPY16TX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "mBwtme2aqMxi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filter those entities that are in knowledge base in at least 1 language (out of 9 taken)\n",
        "\n",
        "val=[True,False]\n",
        "def ch(x):\n",
        "  if x == 'True':\n",
        "    return True\n",
        "  elif x == 'False':\n",
        "    return False\n",
        "  else:\n",
        "    return x\n",
        "data = pd.DataFrame({'qid' : [0],'qid_in_refs': [True]})\n",
        "for nm in glob.glob('dataset/*/mentions.tsv')[:3]:\n",
        "    men = pd.read_csv(nm,sep='\\t', on_bad_lines='skip').dropna()\n",
        "    men['qid_in_refs'] = men['qid_in_refs'].apply(lambda x: ch(x))\n",
        "    men = men.query('qid_in_refs == True').drop_duplicates()\n",
        "    data = data.append(men[['qid','qid_in_refs']], ignore_index=True)\n",
        "  \n",
        "data = data.iloc[1:]\n",
        "good_qid = data.qid.values\n",
        "good_qid = set(good_qid)\n",
        "qid_to_ind=dict(zip(good_qid,np.arange(len(good_qid)).tolist()))"
      ],
      "metadata": {
        "id": "ZKAyXdVaLq0h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_context(link_):\n",
        "  response = requests.get(link_)\n",
        "\n",
        "  if response is not None:\n",
        "      html = BeautifulSoup(response.text, 'html.parser')\n",
        "      title = html.select(\"#firstHeading\")[0].text\n",
        "      paragraphs = html.select(\"p\")\n",
        "\n",
        "      intro = ''.join([ para.text for para in paragraphs[0:5]])\n",
        "      intro = intro.replace('\\n',' ')\n",
        "  else:\n",
        "      intro = None\n",
        "  return intro"
      ],
      "metadata": {
        "id": "iIsSvxNLqjgj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell creates 3 json files mentions_train.json mentions_test.json mentions_val.json\n",
        "\n",
        "prev_index=0\n",
        "full_dict={}\n",
        "lang_folders = glob.glob(f'dataset/*/mentions.tsv')\n",
        "print(lang_folders)\n",
        "for nm in lang_folders:\n",
        "    men = pd.read_csv(nm,sep='\\t', on_bad_lines='skip').query('qid in @good_qid')\n",
        "    men.reset_index(drop=True, inplace=True)\n",
        "    lang=nm[nm.find(os.path.basename(nm))-1-2:nm.find(os.path.basename(nm))-1]\n",
        "    print(lang)\n",
        "    dir_path=os.path.join('dataset',lang)\n",
        "    dict_mens_one_lang=dict()\n",
        "    for index, row in men.iterrows():\n",
        "        one_mention=dict()\n",
        "        path=os.path.join(dir_path,'text',row.docid)\n",
        "        with open(path, 'r') as file:\n",
        "          lines = file.readlines()\n",
        "          lines = [line.rstrip() for line in lines]\n",
        "\n",
        "        title = lines[0].replace(\"'\",\"\").replace('\"','')\n",
        "        text=''.join(lines[1:])\n",
        "        start = text.find(row.mention)            \n",
        "        one_mention[\"start_index\"] = start\n",
        "        one_mention[\"end_index\"] = start+row.length\n",
        "        one_mention[\"mention_its\"] = row.mention\n",
        "        one_mention[\"document_id\"] = row.docid\n",
        "        one_mention[\"mention_id\"] = row.qid\n",
        "        one_mention[\"source_document\"] = {\n",
        "            \"title\": title,\n",
        "            \"text\": text\n",
        "          }\n",
        "        one_mention[\"entity_context\"] = get_context(row.url)\n",
        "        true_index=index+prev_index\n",
        "        dict_mens_one_lang[true_index] = one_mention\n",
        "    full_dict.update(dict_mens_one_lang)\n",
        "    print(len(dict_mens_one_lang))\n",
        "    prev_index+=(index+1)"
      ],
      "metadata": {
        "id": "fgTLF9wNDMDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_size=0.15\n",
        "val_size=0.15\n",
        "random.seed(42)\n",
        "\n",
        "\n",
        "all_ids = np.arange(len(full_dict))\n",
        "\n",
        "test_indexes = random.sample(list(all_ids), int(len(all_ids)*test_size))\n",
        "\n",
        "train_val_indexes = set(all_ids)-set(test_indexes)\n",
        "\n",
        "val_indexes = random.sample(list(train_val_indexes), int(len(train_val_indexes)*val_size))\n",
        "\n",
        "train_indexes = set(train_val_indexes)-set(val_indexes)\n",
        "\n",
        "assert len(full_dict) == len(test_indexes)+len(val_indexes)+len(train_indexes)"
      ],
      "metadata": {
        "id": "cruNI9VGq6Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test-------------------------------\n",
        "values = [full_dict[key] for key in test_indexes]\n",
        "keys=np.arange(len(test_indexes)).tolist()\n",
        "test_dict = dict(zip(keys, values))\n",
        "\n",
        "json_data = json.dumps(test_dict, indent=2, ensure_ascii=False)\n",
        "with open('mentions_test.json', 'w',encoding='utf8') as fp:\n",
        "    fp.write(json_data)\n",
        "\n",
        "#val--------------------------------\n",
        "values = [full_dict[key] for key in val_indexes]\n",
        "keys=np.arange(len(val_indexes)).tolist()\n",
        "val_dict = dict(zip(keys, values))\n",
        "\n",
        "json_data = json.dumps(val_dict, indent=2, ensure_ascii=False)\n",
        "with open('mentions_val.json', 'w',encoding='utf8') as fp:\n",
        "    fp.write(json_data)\n",
        "\n",
        "#train----------------------------\n",
        "values = [full_dict[key] for key in train_indexes]\n",
        "keys=np.arange(len(train_indexes)).tolist()\n",
        "train_dict = dict(zip(keys, values))\n",
        "\n",
        "json_data = json.dumps(train_dict, indent=2, ensure_ascii=False)\n",
        "with open('mentions_train.json', 'w',encoding='utf8') as fp:\n",
        "    fp.write(json_data)"
      ],
      "metadata": {
        "id": "ekx9l-swq4xp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}